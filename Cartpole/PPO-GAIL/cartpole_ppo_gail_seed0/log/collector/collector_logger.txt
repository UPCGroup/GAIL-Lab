[2023-07-19 21:25:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 125
envstep_count: 2486
train_sample_count: 2405
avg_envstep_per_episode: 19.888
avg_sample_per_episode: 19.24
avg_envstep_per_sec: 2548.54192043096
avg_train_sample_per_sec: 2465.5041506984953
avg_episode_per_sec: 128.14470637726066
collect_time: 0.9754597246646881
reward_mean: 19.888
reward_std: 9.33228032155057
reward_max: 60.0
reward_min: 10.0
total_envstep_count: 2592
total_train_sample_count: 2480
total_episode_count: 125
total_duration: 0.9754597246646881
[2023-07-19 21:25:57][sample_serial_collector.py:370][INFO] collect end:
episode_count: 109
envstep_count: 2483
train_sample_count: 2389
avg_envstep_per_episode: 22.779816513761467
avg_sample_per_episode: 21.91743119266055
avg_envstep_per_sec: 2198.540824654665
avg_train_sample_per_sec: 2115.309718123236
avg_episode_per_sec: 96.51266608431675
collect_time: 1.1293854415416718
reward_mean: 22.779816513761467
reward_std: 12.262688839769673
reward_max: 77.0
reward_min: 8.0
total_envstep_count: 5032
total_train_sample_count: 4809
total_episode_count: 234
total_duration: 2.10484516620636
[2023-07-19 21:26:05][sample_serial_collector.py:370][INFO] collect end:
episode_count: 82
envstep_count: 2228
train_sample_count: 2136
avg_envstep_per_episode: 27.170731707317074
avg_sample_per_episode: 26.048780487804876
avg_envstep_per_sec: 2513.256903135866
avg_train_sample_per_sec: 2409.477892772985
avg_episode_per_sec: 92.49868314952471
collect_time: 0.8864991068840027
reward_mean: 27.170731707317074
reward_std: 15.555412263392977
reward_max: 77.0
reward_min: 10.0
total_envstep_count: 7424
total_train_sample_count: 7110
total_episode_count: 316
total_duration: 2.9913442730903625
[2023-07-19 21:26:13][sample_serial_collector.py:370][INFO] collect end:
episode_count: 65
envstep_count: 2509
train_sample_count: 2394
avg_envstep_per_episode: 38.6
avg_sample_per_episode: 36.83076923076923
avg_envstep_per_sec: 2426.2392912394557
avg_train_sample_per_sec: 2315.032627830712
avg_episode_per_sec: 62.855940187550665
collect_time: 1.0341106951236725
reward_mean: 38.6
reward_std: 24.81116374041827
reward_max: 109.0
reward_min: 10.0
total_envstep_count: 9936
total_train_sample_count: 9474
total_episode_count: 381
total_duration: 4.025454968214035
[2023-07-19 21:26:21][sample_serial_collector.py:370][INFO] collect end:
episode_count: 28
envstep_count: 2140
train_sample_count: 2020
avg_envstep_per_episode: 76.42857142857143
avg_sample_per_episode: 72.14285714285714
avg_envstep_per_sec: 2263.4704751739728
avg_train_sample_per_sec: 2136.546897126834
avg_episode_per_sec: 29.615501544332353
collect_time: 0.9454508125782013
reward_mean: 76.42857142857143
reward_std: 33.09987977042101
reward_max: 166.0
reward_min: 22.0
total_envstep_count: 12400
total_train_sample_count: 11824
total_episode_count: 409
total_duration: 4.970905780792236
[2023-07-19 21:26:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 2410
train_sample_count: 2268
avg_envstep_per_episode: 141.76470588235293
avg_sample_per_episode: 133.41176470588235
avg_envstep_per_sec: 2561.076778576365
avg_train_sample_per_sec: 2410.1751592577575
avg_episode_per_sec: 18.065686819833278
collect_time: 0.941010445356369
reward_mean: 141.76470588235293
reward_std: 42.812215700063796
reward_max: 200.0
reward_min: 80.0
total_envstep_count: 14856
total_train_sample_count: 14122
total_episode_count: 426
total_duration: 5.911916226148605
[2023-07-19 21:26:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2235
train_sample_count: 2102
avg_envstep_per_episode: 159.64285714285714
avg_sample_per_episode: 150.14285714285714
avg_envstep_per_sec: 2514.7862687602587
avg_train_sample_per_sec: 2365.136795048798
avg_episode_per_sec: 15.752576180153746
collect_time: 0.88874351978302
reward_mean: 159.64285714285714
reward_std: 28.396697853440493
reward_max: 200.0
reward_min: 120.0
total_envstep_count: 17368
total_train_sample_count: 16479
total_episode_count: 440
total_duration: 6.800659745931625
[2023-07-19 21:26:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 17
envstep_count: 2759
train_sample_count: 2596
avg_envstep_per_episode: 162.2941176470588
avg_sample_per_episode: 152.7058823529412
avg_envstep_per_sec: 2311.9921875934565
avg_train_sample_per_sec: 2175.4011304793817
avg_episode_per_sec: 14.245693073247105
collect_time: 1.1933431327342987
reward_mean: 162.2941176470588
reward_std: 32.56263594237375
reward_max: 200.0
reward_min: 103.0
total_envstep_count: 19808
total_train_sample_count: 18790
total_episode_count: 457
total_duration: 7.994002878665924
[2023-07-19 21:26:54][sample_serial_collector.py:370][INFO] collect end:
episode_count: 13
envstep_count: 2228
train_sample_count: 2094
avg_envstep_per_episode: 171.3846153846154
avg_sample_per_episode: 161.07692307692307
avg_envstep_per_sec: 2436.691350932917
avg_train_sample_per_sec: 2290.139896253828
avg_episode_per_sec: 14.217678439016122
collect_time: 0.9143546223640442
reward_mean: 171.3846153846154
reward_std: 25.891900906352525
reward_max: 200.0
reward_min: 131.0
total_envstep_count: 22336
total_train_sample_count: 21154
total_episode_count: 470
total_duration: 8.908357501029968
[2023-07-19 21:27:02][sample_serial_collector.py:370][INFO] collect end:
episode_count: 14
envstep_count: 2544
train_sample_count: 2393
avg_envstep_per_episode: 181.71428571428572
avg_sample_per_episode: 170.92857142857142
avg_envstep_per_sec: 2512.4095188834062
avg_train_sample_per_sec: 2363.284582817607
avg_episode_per_sec: 13.826153012723148
collect_time: 1.012573778629303
reward_mean: 181.71428571428572
reward_std: 23.211538298959887
reward_max: 200.0
reward_min: 139.0
total_envstep_count: 24744
total_train_sample_count: 23412
total_episode_count: 484
total_duration: 9.920931279659271
