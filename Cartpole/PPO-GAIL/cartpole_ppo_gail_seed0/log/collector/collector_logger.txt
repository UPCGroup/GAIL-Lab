[2023-07-20 11:32:53][sample_serial_collector.py:370][INFO] collect end:
episode_count: 122
envstep_count: 2527
train_sample_count: 2444
avg_envstep_per_episode: 20.71311475409836
avg_sample_per_episode: 20.0327868852459
avg_envstep_per_sec: 1369.2783270862496
avg_train_sample_per_sec: 1324.3040092595147
avg_episode_per_sec: 66.10682861279084
collect_time: 1.8454976975917816
reward_mean: 20.71311475409836
reward_std: 10.505642128295401
reward_max: 56.0
reward_min: 8.0
total_envstep_count: 2624
total_train_sample_count: 2459
total_episode_count: 122
total_duration: 1.8454976975917816
[2023-07-20 11:33:07][sample_serial_collector.py:370][INFO] collect end:
episode_count: 111
envstep_count: 2234
train_sample_count: 2159
avg_envstep_per_episode: 20.126126126126128
avg_sample_per_episode: 19.45045045045045
avg_envstep_per_sec: 1506.0167173346017
avg_train_sample_per_sec: 1455.4566216317837
avg_episode_per_sec: 74.82894164017044
collect_time: 1.4833832681179047
reward_mean: 20.126126126126128
reward_std: 9.19078770763393
reward_max: 58.0
reward_min: 8.0
total_envstep_count: 4968
total_train_sample_count: 4738
total_episode_count: 233
total_duration: 3.3288809657096863
[2023-07-20 11:33:22][sample_serial_collector.py:370][INFO] collect end:
episode_count: 88
envstep_count: 2479
train_sample_count: 2374
avg_envstep_per_episode: 28.170454545454547
avg_sample_per_episode: 26.977272727272727
avg_envstep_per_sec: 1438.9764042566048
avg_train_sample_per_sec: 1378.0274238423476
avg_episode_per_sec: 51.08105025194886
collect_time: 1.7227523624897003
reward_mean: 28.170454545454547
reward_std: 15.161420531093421
reward_max: 75.0
reward_min: 9.0
total_envstep_count: 7408
total_train_sample_count: 7082
total_episode_count: 321
total_duration: 5.051633328199387
[2023-07-20 11:33:38][sample_serial_collector.py:370][INFO] collect end:
episode_count: 57
envstep_count: 2393
train_sample_count: 2273
avg_envstep_per_episode: 41.98245614035088
avg_sample_per_episode: 39.87719298245614
avg_envstep_per_sec: 1578.756648991129
avg_train_sample_per_sec: 1499.5879077128443
avg_episode_per_sec: 37.60515210718527
collect_time: 1.515749752521515
reward_mean: 41.98245614035088
reward_std: 25.353979048987508
reward_max: 119.0
reward_min: 11.0
total_envstep_count: 9896
total_train_sample_count: 9445
total_episode_count: 378
total_duration: 6.5673830807209015
