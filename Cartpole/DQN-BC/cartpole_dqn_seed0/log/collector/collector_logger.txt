[2023-07-20 14:17:30][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 99
train_sample_count: 99
avg_envstep_per_episode: 14.142857142857142
avg_sample_per_episode: 14.142857142857142
avg_envstep_per_sec: 2532.346255440115
avg_train_sample_per_sec: 2532.346255440115
avg_episode_per_sec: 179.05478573818993
collect_time: 0.03909417986869812
reward_mean: 14.142857142857142
reward_std: 4.763809143009448
reward_max: 24.0
reward_min: 9.0
total_envstep_count: 224
total_train_sample_count: 224
total_episode_count: 7
total_duration: 0.03909417986869812
[2023-07-20 14:17:31][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 183
train_sample_count: 183
avg_envstep_per_episode: 22.875
avg_sample_per_episode: 22.875
avg_envstep_per_sec: 2988.6930054259687
avg_train_sample_per_sec: 2988.6930054259687
avg_episode_per_sec: 130.65324613884016
collect_time: 0.06123077869415283
reward_mean: 22.875
reward_std: 5.599944196150529
reward_max: 32.0
reward_min: 15.0
total_envstep_count: 384
total_train_sample_count: 384
total_episode_count: 15
total_duration: 0.10032495856285095
[2023-07-20 14:17:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 7
envstep_count: 166
train_sample_count: 166
avg_envstep_per_episode: 23.714285714285715
avg_sample_per_episode: 23.714285714285715
avg_envstep_per_sec: 2762.6665026602273
avg_train_sample_per_sec: 2762.6665026602273
avg_episode_per_sec: 116.4979850519373
collect_time: 0.06008687615394592
reward_mean: 23.714285714285715
reward_std: 11.707314999170215
reward_max: 46.0
reward_min: 11.0
total_envstep_count: 544
total_train_sample_count: 544
total_episode_count: 22
total_duration: 0.16041183471679688
[2023-07-20 14:17:33][sample_serial_collector.py:370][INFO] collect end:
episode_count: 5
envstep_count: 94
train_sample_count: 94
avg_envstep_per_episode: 18.8
avg_sample_per_episode: 18.8
avg_envstep_per_sec: 1890.257984906063
avg_train_sample_per_sec: 1890.257984906063
avg_episode_per_sec: 100.54563749500335
collect_time: 0.04972866177558899
reward_mean: 18.8
reward_std: 5.230678732248808
reward_max: 25.0
reward_min: 13.0
total_envstep_count: 704
total_train_sample_count: 704
total_episode_count: 27
total_duration: 0.21014049649238586
[2023-07-20 14:17:34][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 222
train_sample_count: 222
avg_envstep_per_episode: 27.75
avg_sample_per_episode: 27.75
avg_envstep_per_sec: 2217.1786411517887
avg_train_sample_per_sec: 2217.1786411517887
avg_episode_per_sec: 79.89832941087528
collect_time: 0.10012724995613098
reward_mean: 27.75
reward_std: 12.356678356257397
reward_max: 53.0
reward_min: 12.0
total_envstep_count: 864
total_train_sample_count: 864
total_episode_count: 35
total_duration: 0.31026774644851685
[2023-07-20 14:17:35][sample_serial_collector.py:370][INFO] collect end:
episode_count: 8
envstep_count: 197
train_sample_count: 197
avg_envstep_per_episode: 24.625
avg_sample_per_episode: 24.625
avg_envstep_per_sec: 3188.381709242908
avg_train_sample_per_sec: 3188.381709242908
avg_episode_per_sec: 129.47742981697087
collect_time: 0.06178683042526245
reward_mean: 24.625
reward_std: 18.23415407963857
reward_max: 71.0
reward_min: 12.0
total_envstep_count: 1024
total_train_sample_count: 1024
total_episode_count: 43
total_duration: 0.3720545768737793
