[2023-07-19 10:12:29][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 201
train_sample_count: 201
avg_envstep_per_episode: 18.272727272727273
avg_sample_per_episode: 18.272727272727273
avg_envstep_per_sec: 1310.9003710865068
avg_train_sample_per_sec: 1310.9003710865068
avg_episode_per_sec: 71.74081632811729
collect_time: 0.1533297300338745
reward_mean: 18.272727272727273
reward_std: 7.604913592132501
reward_max: 34.0
reward_min: 9.0
total_envstep_count: 336
total_train_sample_count: 336
total_episode_count: 11
total_duration: 0.1533297300338745
[2023-07-19 10:12:32][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 306
train_sample_count: 306
avg_envstep_per_episode: 25.5
avg_sample_per_episode: 25.5
avg_envstep_per_sec: 2697.0281243154104
avg_train_sample_per_sec: 2697.0281243154104
avg_episode_per_sec: 105.76580879668276
collect_time: 0.11345821619033813
reward_mean: 25.5
reward_std: 16.322275168206996
reward_max: 64.0
reward_min: 10.0
total_envstep_count: 608
total_train_sample_count: 608
total_episode_count: 23
total_duration: 0.26678794622421265
[2023-07-19 10:12:37][sample_serial_collector.py:370][INFO] collect end:
episode_count: 12
envstep_count: 283
train_sample_count: 283
avg_envstep_per_episode: 23.583333333333332
avg_sample_per_episode: 23.583333333333332
avg_envstep_per_sec: 2867.334688305559
avg_train_sample_per_sec: 2867.334688305559
avg_episode_per_sec: 121.58309632391062
collect_time: 0.09869793057441711
reward_mean: 23.583333333333332
reward_std: 11.101488889133545
reward_max: 46.0
reward_min: 10.0
total_envstep_count: 880
total_train_sample_count: 880
total_episode_count: 35
total_duration: 0.36548587679862976
[2023-07-19 10:12:40][sample_serial_collector.py:370][INFO] collect end:
episode_count: 15
envstep_count: 287
train_sample_count: 287
avg_envstep_per_episode: 19.133333333333333
avg_sample_per_episode: 19.133333333333333
avg_envstep_per_sec: 2386.14171817372
avg_train_sample_per_sec: 2386.14171817372
avg_episode_per_sec: 124.7112396258042
collect_time: 0.12027785181999207
reward_mean: 19.133333333333333
reward_std: 6.312597634008434
reward_max: 33.0
reward_min: 12.0
total_envstep_count: 1152
total_train_sample_count: 1152
total_episode_count: 50
total_duration: 0.4857637286186218
[2023-07-19 10:12:46][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 227
train_sample_count: 227
avg_envstep_per_episode: 22.7
avg_sample_per_episode: 22.7
avg_envstep_per_sec: 2844.3392449307294
avg_train_sample_per_sec: 2844.3392449307294
avg_episode_per_sec: 125.30128832293961
collect_time: 0.07980763912200928
reward_mean: 22.7
reward_std: 11.428473213863695
reward_max: 51.0
reward_min: 9.0
total_envstep_count: 1424
total_train_sample_count: 1424
total_episode_count: 60
total_duration: 0.5655713677406311
[2023-07-19 10:12:50][sample_serial_collector.py:370][INFO] collect end:
episode_count: 11
envstep_count: 256
train_sample_count: 256
avg_envstep_per_episode: 23.272727272727273
avg_sample_per_episode: 23.272727272727273
avg_envstep_per_sec: 2832.875120373375
avg_train_sample_per_sec: 2832.875120373375
avg_episode_per_sec: 121.72510282854346
collect_time: 0.09036755561828613
reward_mean: 23.272727272727273
reward_std: 8.421734965831611
reward_max: 39.0
reward_min: 12.0
total_envstep_count: 1696
total_train_sample_count: 1696
total_episode_count: 71
total_duration: 0.6559389233589172
[2023-07-19 10:13:06][sample_serial_collector.py:370][INFO] collect end:
episode_count: 10
envstep_count: 271
train_sample_count: 271
avg_envstep_per_episode: 27.1
avg_sample_per_episode: 27.1
avg_envstep_per_sec: 2910.278048858548
avg_train_sample_per_sec: 2910.278048858548
avg_episode_per_sec: 107.3903339062195
collect_time: 0.09311825037002563
reward_mean: 27.1
reward_std: 7.39526875779373
reward_max: 38.0
reward_min: 16.0
total_envstep_count: 1968
total_train_sample_count: 1968
total_episode_count: 81
total_duration: 0.7490571737289429
